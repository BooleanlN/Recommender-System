{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelPractice.Model import Model\n",
    "class Logistic(Model):\n",
    "    def __init__(self,X,Y,learning_rate,with_regular=False,penalty='l1',C=1.0):\n",
    "        super().__init__(name='logistic')\n",
    "        self.X = np.array(X)\n",
    "        bias = np.zeros(len(X))\n",
    "        self.X = np.insert(self.X,0,values=bias,axis=1)\n",
    "        self.y = np.array(Y)\n",
    "        self.weight = self.initWeight()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.with_regular = with_regular\n",
    "        self.C = C\n",
    "        self.penalty = penalty\n",
    "    def train(self,epochs):\n",
    "        \"\"\"train model\"\"\"\n",
    "        self.stochasticGD(epochs)\n",
    "    def stochasticGD(self,epochs):\n",
    "        \"\"\"随机梯度下降\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            print(\">>>>第{}轮训练开始>>>\\n\".format(str(epoch)))\n",
    "            for index,x in enumerate(self.X): \n",
    "    #                 print(self.learning_rate * (self.y[index] - self.sigmoid(x)))\n",
    "                if not self.with_regular:\n",
    "                    self.weight = self.weight + self.learning_rate * (self.y[index] - self.sigmoid(x)) * x \n",
    "                else:\n",
    "                    if self.penalty == 'l1':\n",
    "                        self.weight = self.weight + self.learning_rate * (self.y[index] - self.sigmoid(x)) * x + self.C * self.weight\n",
    "                    else:\n",
    "                        self.weight = self.weight + self.learning_rate * (self.y[index] - self.sigmoid(x)) * x + self.C\n",
    "            print(\">>>>当前accuracy：{}>>>>>>\\n\".format(self.loss()))\n",
    "    def batchGD(self,epochs):\n",
    "        \"\"\"梯度下降\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            print(\">>>>第{}轮训练开始>>>\\n\".format(str(epoch)))\n",
    "            loss = np.zeros(self.X.shape[1])\n",
    "            for index,x in enumerate(self.X):\n",
    "                loss =loss + (self.y[index] - self.sigmoid(x)) * x\n",
    "            if not self.with_regular:\n",
    "                self.weight = self.weight + self.learning_rate * loss\n",
    "            else:\n",
    "                if self.penalty == 'l1':\n",
    "                    self.weight = self.weight + self.learning_rate * loss + self.C\n",
    "                else:\n",
    "                    self.weight = self.weight + self.learning_rate * loss + self.C * self.weight  \n",
    "            #self.weight = self.weight + self.learning_rate * np.sum((self.y - np.apply_along_axis(self.sigmoid,1,self.X))*self.X.T)\n",
    "            print(\">>>>当前accuracy：{}>>>>>>\\n\".format(self.loss()))\n",
    "    def miniBatchGD(self,epochs,batch_size=20):\n",
    "        \"\"\"小批量样本梯度下降\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            start = 0\n",
    "            print(\">>>>第{}轮训练开始>>>\\n\".format(str(epoch)))\n",
    "            for start in range(0,self.X.shape[0],batch_size):\n",
    "                loss = np.zeros(self.X.shape[1])\n",
    "                for index,x in enumerate(self.X[start:start+batch_size]):\n",
    "                    loss =loss + (self.y[index] - self.sigmoid(x)) * x\n",
    "                if not self.with_regular:\n",
    "                    self.weight = self.weight + self.learning_rate *(1/batch_size) * loss\n",
    "                else:\n",
    "                    if penalty == 'l1':\n",
    "                        self.weight = self.weight + self.learning_rate *(1/batch_size) * loss + self.C\n",
    "                    else:\n",
    "                        self.weight = self.weight + self.learning_rate *(1/batch_size) * loss + self.C * \n",
    "            print(\">>>>当前accuracy：{}>>>>>>\\n\".format(self.loss()))\n",
    "    def predict(self,X_test,y_test=None):\n",
    "        \"\"\"accuracy rate\"\"\"\n",
    "        correct_num = 0\n",
    "        bias = np.zeros(len(X_test))\n",
    "        X_test = np.insert(X_test,0,values=bias,axis=1)\n",
    "        for index,x in enumerate(X_test): \n",
    "            pre = self.sigmoid(x)\n",
    "            pre_y = 0\n",
    "            if pre > 0.5:\n",
    "                pre_y = 1\n",
    "            if pre_y == y_test[index]:\n",
    "                correct_num += 1\n",
    "        return correct_num / len(X_test)\n",
    "    def initWeight(self):\n",
    "        return np.zeros(len(self.X[0]))\n",
    "    def sigmoid(self,x):\n",
    "        \"\"\"sigmoid func\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.sum(np.dot(x,self.weight.T))))\n",
    "    def loss(self):\n",
    "        \"\"\"current accuracy\"\"\"\n",
    "        correct_num = 0.0\n",
    "        for index,x in enumerate(self.X):\n",
    "            pre = self.sigmoid(x)\n",
    "            pre_y = 0\n",
    "            if pre > 0.5:\n",
    "                pre_y = 1\n",
    "            if pre_y == self.y[index]:\n",
    "                correct_num += 1\n",
    "        return correct_num / len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=0.3)\n",
    "LR = Logistic(X_train,y_train,0.6,with_regular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>第0轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第1轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第2轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第3轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第4轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第5轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第6轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第7轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第8轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第9轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第10轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第11轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第12轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第13轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第14轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第15轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第16轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第17轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第18轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第19轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第20轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第21轮训练开始>>>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:81: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第22轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第23轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第24轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第25轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第26轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第27轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第28轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第29轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第30轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第31轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第32轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第33轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第34轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第35轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第36轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第37轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第38轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第39轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第40轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第41轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第42轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第43轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第44轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第45轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第46轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第47轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第48轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第49轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第50轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第51轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第52轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第53轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第54轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第55轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第56轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第57轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第58轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第59轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第60轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第61轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第62轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第63轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第64轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第65轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第66轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第67轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第68轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第69轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第70轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第71轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第72轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第73轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第74轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第75轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第76轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第77轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第78轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第79轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第80轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第81轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第82轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第83轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第84轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第85轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第86轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第87轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第88轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第89轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第90轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第91轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第92轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第93轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第94轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第95轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第96轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第97轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第98轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n",
      ">>>>第99轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3693467336683417>>>>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:81: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38011695906432746"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.predict(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  2.30716657e+03,  2.40669307e+03,  1.17958325e+04,\n",
       "        4.94976560e+03,  3.41140234e+00, -6.18920547e+01, -1.11235772e+02,\n",
       "       -5.06340509e+01,  1.06382308e+01,  8.64655120e+00, -1.66004431e+01,\n",
       "        1.67430642e+02, -4.03136071e+02, -8.58931870e+03,  3.52256409e-03,\n",
       "       -1.26600462e+01, -1.95377901e+01, -5.03635379e+00, -3.01251419e-01,\n",
       "       -4.94347930e-01,  2.37357793e+03,  1.36012707e+03,  1.07229749e+04,\n",
       "       -6.02027136e+03, -2.73142369e+00, -2.16734693e+02, -2.95653020e+02,\n",
       "       -8.89247998e+01, -2.08739949e+01, -2.73339063e+00])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
