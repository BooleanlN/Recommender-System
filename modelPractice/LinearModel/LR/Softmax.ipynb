{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelPractice.Model import Model\n",
    "class Softmax(Model):\n",
    "    def __init__(self,X,Y,classes,learning_rate=0.1,with_regular=False,penalty='l1',C=1.0):\n",
    "        super().__init__(name='softmax regression')\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(Y)\n",
    "        self.classes = classes\n",
    "        self.bias = np.zeros((1,self.classes))\n",
    "        self.weight = self.initWeight()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.with_regular = with_regular\n",
    "        self.C = C\n",
    "        self.penalty = penalty\n",
    "    def train(self,epochs):\n",
    "        \"\"\"train model\"\"\"\n",
    "        self.batchGD(epochs)\n",
    "    def batchGD(self,epochs):\n",
    "        \"\"\"梯度下降\"\"\"\n",
    "        y_onehot = self.oneHot()\n",
    "        for epoch in range(epochs):\n",
    "            print(\">>>>第{}轮训练开始>>>\\n\".format(str(epoch)))\n",
    "            pred = self.softmax(self.X)\n",
    "            scores = self.computeScores(self.X)\n",
    "            dw = (1 / self.X.shape[0]) * np.dot(self.X.T, (pred - y_onehot))\n",
    "            db = (1 / self.X.shape[0]) * np.sum(pred - y_onehot, axis=0)\n",
    "            self.weight = self.weight - self.learning_rate * dw.T\n",
    "            self.bias = self.bias - self.learning_rate * db\n",
    "            print(\">>>>当前accuracy：{}>>>>>>\\n\".format(self.accuracy(self.X,self.y)))\n",
    "            print(\">>>>当前loss：{}>>>>>>>\\n\".format(self.crossEntropyLoss(scores)))\n",
    "    def predict(self,X_test,y_test):\n",
    "        \"\"\"accuracy rate\"\"\"\n",
    "        return self.accuracy(X_test,y_test)\n",
    "    def initWeight(self):\n",
    "        \"\"\"权重初始化 shape = (classes,n_features)\"\"\"\n",
    "        return np.random.rand(self.classes,self.X.shape[1])\n",
    "    def softmax(self,X):\n",
    "        \"\"\"softmax func\"\"\"\n",
    "        scores = self.computeScores(X)\n",
    "        return np.exp(scores) / np.sum(np.exp(scores),axis=1,keepdims=True)\n",
    "    def computeScores(self,X):\n",
    "        return np.dot(X, self.weight.T) + self.bias\n",
    "    def oneHot(self):\n",
    "        \"\"\"Y转为one hot\"\"\"\n",
    "        hots = np.zeros(shape=(self.X.shape[0],self.classes))\n",
    "        for index,y_val in enumerate(self.y):\n",
    "            hots[index][y_val] = 1\n",
    "        return hots\n",
    "    def accuracy(self,X,y):\n",
    "        \"\"\"current accuracy\"\"\"\n",
    "        correct_num = 0.0\n",
    "        pre = self.softmax(X)\n",
    "        for index,pred_y in enumerate(pre):\n",
    "            pred = np.argmax(pred_y)\n",
    "            if pred == y[index]:\n",
    "                correct_num += 1\n",
    "        return correct_num / len(X)\n",
    "    def crossEntropyLoss(self,scores):\n",
    "        y_true = self.oneHot()\n",
    "        loss = - (1 / self.X.shape[0]) * np.sum(y_true* np.log(scores))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=0.3)\n",
    "SR = Softmax(X_train,y_train,learning_rate=0.01,classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>第0轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.03341288782816229>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.023209393552985>>>>>>>\n",
      "\n",
      ">>>>第1轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.04136833731105807>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.028491137936715>>>>>>>\n",
      "\n",
      ">>>>第2轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.042163882259347654>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.033042635955238>>>>>>>\n",
      "\n",
      ">>>>第3轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.053301511535401754>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.037219293591799>>>>>>>\n",
      "\n",
      ">>>>第4轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.061256961018297536>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.041172126232563>>>>>>>\n",
      "\n",
      ">>>>第5轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.07000795544948289>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.044966121067647>>>>>>>\n",
      "\n",
      ">>>>第6轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.07637231503579953>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.048627940546294>>>>>>>\n",
      "\n",
      ">>>>第7轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.08194112967382657>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.0521719701853876>>>>>>>\n",
      "\n",
      ">>>>第8轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.09387430389817025>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.0556106979175865>>>>>>>\n",
      "\n",
      ">>>>第9轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.10978520286396182>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.058948351098745>>>>>>>\n",
      "\n",
      ">>>>第10轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.12410501193317422>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.062185178369562>>>>>>>\n",
      "\n",
      ">>>>第11轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.13762927605409706>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.065316067023874>>>>>>>\n",
      "\n",
      ">>>>第12轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.15513126491646778>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.06833239498953>>>>>>>\n",
      "\n",
      ">>>>第13轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.1726332537788385>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.071229330797124>>>>>>>\n",
      "\n",
      ">>>>第14轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.19252187748607796>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.07400712123231>>>>>>>\n",
      "\n",
      ">>>>第15轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.2100238663484487>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.0766673021104545>>>>>>>\n",
      "\n",
      ">>>>第16轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.22911694510739858>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.0792115231013435>>>>>>>\n",
      "\n",
      ">>>>第17轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.24821002386634844>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.081642173678317>>>>>>>\n",
      "\n",
      ">>>>第18轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.27048528241845665>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.083962771784487>>>>>>>\n",
      "\n",
      ">>>>第19轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.2856006364359586>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.0861782510890725>>>>>>>\n",
      "\n",
      ">>>>第20轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3015115354017502>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.088294534062405>>>>>>>\n",
      "\n",
      ">>>>第21轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3221957040572792>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.09031724982214>>>>>>>\n",
      "\n",
      ">>>>第22轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3317422434367542>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.09225075921151>>>>>>>\n",
      "\n",
      ">>>>第23轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.3524264120922832>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.094097846770821>>>>>>>\n",
      "\n",
      ">>>>第24轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.36515513126491644>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.095860234658695>>>>>>>\n",
      "\n",
      ">>>>第25轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.38902147971360385>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.097539669769544>>>>>>>\n",
      "\n",
      ">>>>第26轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.4033412887828162>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.099138644431095>>>>>>>\n",
      "\n",
      ">>>>第27轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.4224343675417661>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.100660340610329>>>>>>>\n",
      "\n",
      ">>>>第28轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.43675417661097854>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.1021082780792435>>>>>>>\n",
      "\n",
      ">>>>第29轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.4606205250596659>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.103486100848364>>>>>>>\n",
      "\n",
      ">>>>第30轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.47653142402545745>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.104797634099094>>>>>>>\n",
      "\n",
      ">>>>第31轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.4821002386634845>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.10604681623086>>>>>>>\n",
      "\n",
      ">>>>第32轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.4996022275258552>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.107237418285653>>>>>>>\n",
      "\n",
      ">>>>第33轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5171042163882259>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.10837289190971>>>>>>>\n",
      "\n",
      ">>>>第34轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5322195704057279>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.109456510469189>>>>>>>\n",
      "\n",
      ">>>>第35轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5449482895783612>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.110491590246741>>>>>>>\n",
      "\n",
      ">>>>第36轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5544948289578361>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.111481536020312>>>>>>>\n",
      "\n",
      ">>>>第37轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5616547334924423>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.112429711754477>>>>>>>\n",
      "\n",
      ">>>>第38轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5704057279236276>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.113339291006221>>>>>>>\n",
      "\n",
      ">>>>第39轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5807478122513922>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.114213175658926>>>>>>>\n",
      "\n",
      ">>>>第40轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5910898965791567>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.115053973288149>>>>>>>\n",
      "\n",
      ">>>>第41轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.5958631662688942>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.115864000407851>>>>>>>\n",
      "\n",
      ">>>>第42轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6030230708035004>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.116645299587964>>>>>>>\n",
      "\n",
      ">>>>第43轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6101829753381066>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.117399670976676>>>>>>>\n",
      "\n",
      ">>>>第44轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6173428798727129>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.118128713303292>>>>>>>\n",
      "\n",
      ">>>>第45轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6260938743038982>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.118833863584588>>>>>>>\n",
      "\n",
      ">>>>第46轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6332537788385044>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.119516428223002>>>>>>>\n",
      "\n",
      ">>>>第47轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6372315035799523>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.120177605377338>>>>>>>\n",
      "\n",
      ">>>>第48轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6420047732696897>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.120818501797585>>>>>>>\n",
      "\n",
      ">>>>第49轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.649164677804296>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.1214401460547725>>>>>>>\n",
      "\n",
      ">>>>第50轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6563245823389021>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.122043498103964>>>>>>>\n",
      "\n",
      ">>>>第51轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6587112171837709>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.122629455081858>>>>>>>\n",
      "\n",
      ">>>>第52轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6610978520286396>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.123198854591597>>>>>>>\n",
      "\n",
      ">>>>第53轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.664280031821798>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.123752477482022>>>>>>>\n",
      "\n",
      ">>>>第54轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6706443914081146>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.124291051462581>>>>>>>\n",
      "\n",
      ">>>>第55轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6738265712012729>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.124815255624887>>>>>>>\n",
      "\n",
      ">>>>第56轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6801909307875895>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.125325725181645>>>>>>>\n",
      "\n",
      ">>>>第57轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6865552903739062>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.125823055771914>>>>>>>\n",
      "\n",
      ">>>>第58轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.690533015115354>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.126307807073957>>>>>>>\n",
      "\n",
      ">>>>第59轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.6937151949085123>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.126780505748428>>>>>>>\n",
      "\n",
      ">>>>第60轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7008750994431185>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.127241647816311>>>>>>>\n",
      "\n",
      ">>>>第61轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7072394590294352>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.127691700594923>>>>>>>\n",
      "\n",
      ">>>>第62轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7096260938743039>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.128131104359995>>>>>>>\n",
      "\n",
      ">>>>第63轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7136038186157518>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.128560273943851>>>>>>>\n",
      "\n",
      ">>>>第64轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7175815433571997>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.128979600461432>>>>>>>\n",
      "\n",
      ">>>>第65轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.720763723150358>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.129389453264609>>>>>>>\n",
      "\n",
      ">>>>第66轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7223548130469372>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.12979018209574>>>>>>>\n",
      "\n",
      ">>>>第67轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7255369928400954>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.130182119295327>>>>>>>\n",
      "\n",
      ">>>>第68轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7279236276849642>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.1305655818579075>>>>>>>\n",
      "\n",
      ">>>>第69轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7295147175815434>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.13094087314238>>>>>>>\n",
      "\n",
      ">>>>第70轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7311058074781225>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.131308284116837>>>>>>>\n",
      "\n",
      ">>>>第71轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7366746221161495>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.1316680941212>>>>>>>\n",
      "\n",
      ">>>>第72轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7382657120127287>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.13202057122577>>>>>>>\n",
      "\n",
      ">>>>第73轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7430389817024662>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.132365972323118>>>>>>>\n",
      "\n",
      ">>>>第74轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7446300715990454>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.132704543106357>>>>>>>\n",
      "\n",
      ">>>>第75轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.745425616547335>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.133036518067185>>>>>>>\n",
      "\n",
      ">>>>第76轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.747016706443914>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.133362120607528>>>>>>>\n",
      "\n",
      ">>>>第77轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7478122513922036>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.13368156331425>>>>>>>\n",
      "\n",
      ">>>>第78轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7494033412887828>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.1339950484069785>>>>>>>\n",
      "\n",
      ">>>>第79轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7549721559268099>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.134302768339035>>>>>>>\n",
      "\n",
      ">>>>第80轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7549721559268099>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.134604906511391>>>>>>>\n",
      "\n",
      ">>>>第81轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7565632458233891>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.134901638048653>>>>>>>\n",
      "\n",
      ">>>>第82轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7597454256165473>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.135193130582941>>>>>>>\n",
      "\n",
      ">>>>第83轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.762132060461416>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.135479544995279>>>>>>>\n",
      "\n",
      ">>>>第84轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7653142402545744>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.135761036073588>>>>>>>\n",
      "\n",
      ">>>>第85轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7669053301511536>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.136037753059903>>>>>>>\n",
      "\n",
      ">>>>第86轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7692919649960223>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.136309840074789>>>>>>>\n",
      "\n",
      ">>>>第87轮训练开始>>>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>当前accuracy：0.7724741447891806>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.136577436421494>>>>>>>\n",
      "\n",
      ">>>>第88轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7732696897374701>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.136840676783933>>>>>>>\n",
      "\n",
      ">>>>第89轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7764518695306285>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.137099691340011>>>>>>>\n",
      "\n",
      ">>>>第90轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7796340493237868>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.137354605814982>>>>>>>\n",
      "\n",
      ">>>>第91轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.781225139220366>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.137605541499284>>>>>>>\n",
      "\n",
      ">>>>第92轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7828162291169452>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.137852615252726>>>>>>>\n",
      "\n",
      ">>>>第93轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7852028639618138>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.138095939513125>>>>>>>\n",
      "\n",
      ">>>>第94轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7859984089101034>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.138335622323057>>>>>>>\n",
      "\n",
      ">>>>第95轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.786793953858393>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.138571767383817>>>>>>>\n",
      "\n",
      ">>>>第96轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7899761336515513>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.138804474141031>>>>>>>\n",
      "\n",
      ">>>>第97轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7915672235481305>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.13903383790201>>>>>>>\n",
      "\n",
      ">>>>第98轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7915672235481305>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.139259949980932>>>>>>>\n",
      "\n",
      ">>>>第99轮训练开始>>>\n",
      "\n",
      ">>>>当前accuracy：0.7923627684964201>>>>>>\n",
      "\n",
      ">>>>当前loss：-5.139482897864857>>>>>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SR.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SR.predict(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 22])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([[0,1,2,3],[4,5,6,7]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
