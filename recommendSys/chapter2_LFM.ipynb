{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐语义模型(latent factor model)\n",
    "该模型算法最早在文本挖掘领域被提出，用于找到文本的隐含语义。相关模型有pLSA、LDA、隐含类别模型、隐含主题模型、主题分解等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LFM模型是如何用于RecSys的呢？<br>\n",
    "\n",
    "与CF不同，我们考虑通过用户的兴趣分类，再从他的兴趣分类中，挑选他可能喜欢的物品。<br>\n",
    "\n",
    "如何得到他的兴趣分类呢? <br>\n",
    "\n",
    "主要通过分析其有过行为的物品，根据这些物品的分类，推断 <br>\n",
    "\n",
    "物品的分类又是怎么得到的呢？  \n",
    "\n",
    "LFM模型可以基于用户行为统计，对物品进行自动聚类  \n",
    "\n",
    "LFM模型通过以下公式衡量用户对物品的兴趣：  \n",
    "$$\n",
    "Preference(u,i) = r_{ui} = p_u^Tq_i = \\sum_{k=1}^{K}p_{u,k}q_{i,k}\n",
    "$$\n",
    "其中`p_uk`表示用户u对分类k的兴趣，`q_ik`表示物品i与分类k的关联"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LFM模型在显性反馈数据上，可以很好地解决评分预测问题。在隐性反馈数据上，因为只有正样本，因此需要生成负样本。  \n",
    "生成原则：  \n",
    "- 对每个用户，要保证正负样本的平衡\n",
    "- 对每个用户采样负样本时，要选取那些很热门，而用户没有行为的物品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 负采样\n",
    "def randomSelectNegativeSample(items,item_pool):\n",
    "    ret = {}\n",
    "    for i in items.keys():\n",
    "        ret[i] = 1\n",
    "    n_negative = 0\n",
    "    while n_negative < len(items):\n",
    "        item = random.choice(item_pool)\n",
    "        if item in ret:\n",
    "            continue\n",
    "        n_negative += 1\n",
    "        ret[item] = 0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "LFM模型通过优化如下的平方损失函数，得到p、q参数：\n",
    "$$\n",
    "loss = \\sum_{(u,i)\\in K}(r_{ui} - r*_{ui})^2 = \\sum_{(u,i)\\in K}(r_{ui} - \\sum_{k=1}^{K}p_{u,k}q_{i,k})^2 + \n",
    "\\lambda \\lVert p_u \\rVert ^2 + \\lambda \\lVert q_i \\rVert ^2\n",
    "$$\n",
    "其中，`λp+λq`是用来防止过拟合的正则化项。  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loss(train_set,l,user_p,movie_q):\n",
    "    def predict(user,movie):\n",
    "        return np.dot(user_p[user],movie_p[movie])\n",
    "    C = 0\n",
    "    for user,p_val in user_p.items():\n",
    "        for movie,q_val in movie_q.items():\n",
    "            user_train_set = train_set[user]\n",
    "            if movie not in user_train_set:\n",
    "                continue\n",
    "            rui = train_set[movie]\n",
    "            eui = rui - predict(user,movie)\n",
    "            C += (np.square(eui) + l * np.sum(np.square(user_p[user]))) + l * np.sum(np.square(movie_p[movie]))\n",
    "    return C        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用随机梯度下降算法对损失函数进行优化。\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial p_{uk}} = -2q_{ik} + 2\\lambda p_{uk} \\\\\n",
    "\\frac{\\partial C}{\\partial q_{ik}} = -2p_{uk} + 2\\lambda q_{ik} \\\\\n",
    "p_{uk} = p_{uk} + \\alpha(q_{ik} - \\lambda p_{uk}) \\\\\n",
    "q_{ik} = q_{ik} + \\alpha(p_{uk} - \\lambda q_{ik})\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(user_p,movie_q,movies_pool,epoches,learning_rate,l):\n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        print(\"第{}轮训练begainning...\".format(epoch))\n",
    "        for user,user_items in train_set.items():\n",
    "            samples = randomSelectNegativeSample(user_items,movies_pool)\n",
    "            for movie,rui in samples.items():\n",
    "                user_latent = user_p[user]\n",
    "                movie_latent = movie_q[movie]\n",
    "                user_p[user] += learning_rate * (movie_latent - l*user_latent)\n",
    "                movie_q[movie] += learning_rate * (user_latent - l*movie_latent)\n",
    "        loss = loss(samples,l,user_p,movie_q)\n",
    "        print(\"第{}轮,loss is {}\".format(epoch,loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init(train_data,k):\n",
    "    user_p = {}\n",
    "    movie_q = {}\n",
    "    movie_pool = set()\n",
    "    print(\"初始化参数...\")\n",
    "    for user,movies in train_data.items():\n",
    "        user_p[user] = np.random.normal(size=(k))\n",
    "        for movie in movies.items():\n",
    "            movie_pool.add(movie[0])\n",
    "    for movie in movie_pool:\n",
    "        movie_q[movie] = np.random.normal(size=(k))\n",
    "    return user_p,movie_q,movie_pool"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "def load_data(users_path,movies_path,rating_path):\n",
    "    \n",
    "    def read_users():\n",
    "        \"\"\"(user_id:(gender,age,occupation))\"\"\"\n",
    "        users = {}\n",
    "        with open(users_path,'r') as f:\n",
    "            users = {line.split(\"::\")[0]:line.split(\"::\")[1:-1] for line in f.readlines()}\n",
    "        return users\n",
    "    def read_movies():\n",
    "        \"\"\"(movie_id:(title,genres))\"\"\"\n",
    "        movies = {}\n",
    "        with open(movies_path,'r') as f:\n",
    "            movies = {line.split(\"::\")[0]: line.split(\"::\")[1:] for line in f.readlines()}\n",
    "        return movies\n",
    "    def read_ratings():\n",
    "        \"\"\"{user_id:{movie_id: rating}}\"\"\"\n",
    "        ratings = dict()\n",
    "        with open(rating_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                user,movie,rating,_ = line.split('::')\n",
    "                ratings.setdefault(user,{})\n",
    "                ratings[user][movie] = int(rating)\n",
    "        return ratings\n",
    "    return read_users(),read_movies(),read_ratings()\n",
    "def split_train_test(data,M,k,seed):\n",
    "    \"\"\"M折交叉验证\"\"\"\n",
    "    train_set = dict()\n",
    "    test_set = dict()\n",
    "    random.seed(seed)\n",
    "    test_count,train_count = 0,0\n",
    "    for user,movie_info in data.items():\n",
    "        for movie,rating in movie_info.items():\n",
    "            if random.randint(0,M) == k:\n",
    "                test_set.setdefault(user,{})\n",
    "                test_set[user][movie] = int(rating)\n",
    "                test_count += 1\n",
    "            else:\n",
    "                train_set.setdefault(user,{})\n",
    "                train_set[user][movie] = int(rating)\n",
    "                train_count += 1\n",
    "    print(test_count,train_count)\n",
    "    return train_set,test_set\n",
    "USERS_PATH = '../dataset/ml-1m/users.dat'\n",
    "MOVIES_PATH = '../dataset/ml-1m/movies.dat'\n",
    "RATINGS_PATH = '../dataset/ml-1m/ratings.dat'\n",
    "users,movies,ratings = load_data(USERS_PATH,MOVIES_PATH,RATINGS_PATH)\n",
    "train_set,test_set = split_train_test(ratings,5,1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_p,movie_q,movies_pool = init(train_set,100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_p['1'],movie_q['661']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(user_p,movie_q,list(movies_pool),500,learning_rate=0.02,l=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def recommand(user):\n",
    "    def predict(user,movie):\n",
    "        return np.dot(user_p[user],movie_p[movie])\n",
    "    rank = defaultdict(int)\n",
    "    for movie in list(movies_pool):\n",
    "        rank[movie] = predict(user,movie)\n",
    "    return sorted(rank.items(),key=itemgetter(1),reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hit(train,test,N):\n",
    "    hit = 0\n",
    "    for user in train.keys():\n",
    "        real = test[user] if user in test else []\n",
    "        recommand_items = recommand(user)[:N]\n",
    "        for item in recommand_items:\n",
    "            if item[0] in real:\n",
    "                hit += 1\n",
    "    print('hit:%d'% hit)\n",
    "    return hit\n",
    "# precision\n",
    "def Precision(train,hit,N):\n",
    "    print('sum:%d' % (len(train.keys()) * N))\n",
    "    return hit / len(train.keys()) * N\n",
    "# recall\n",
    "def Recall(train,test,hit):\n",
    "    recommands = 0\n",
    "    for user in train.keys():\n",
    "        real = test[user] if user in test else []\n",
    "        recommands += len(real)\n",
    "    print('sum_real: %d' % recommands)\n",
    "    return hit / recommands "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hit_total = hit(train_set,test_set,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Precision(train_set,hit,10),Recall(train_set,hit,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loss(train_set,l,user_p,movie_q):\n",
    "    def predict(user,movie):\n",
    "        return np.dot(user_p[user],movie_p[movie])\n",
    "    C = 0\n",
    "    for user,p_val in user_p.items():\n",
    "        for movie,q_val in movie_q.items():\n",
    "            user_train_set = train_set[user]\n",
    "            if movie not in user_train_set:\n",
    "                continue\n",
    "            rui = train_set[movie]\n",
    "            eui = rui - predict(user,movie)\n",
    "            C += (np.square(eui) + l * np.sum(np.square(user_p[user]))) + l * np.sum(np.square(movie_p[movie]))\n",
    "    return C        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用随机梯度下降算法对损失函数进行优化。\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial p_{uk}} = -2q_{ik} + 2\\lambda p_{uk} \\\\\n",
    "\\frac{\\partial C}{\\partial q_{ik}} = -2p_{uk} + 2\\lambda q_{ik} \\\\\n",
    "p_{uk} = p_{uk} + \\alpha(q_{ik} - \\lambda p_{uk}) \\\\\n",
    "q_{ik} = q_{ik} + \\alpha(p_{uk} - \\lambda q_{ik})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(user_p,movie_q,movies_pool,epoches,learning_rate,l):\n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        print(\"第{}轮训练begainning...\".format(epoch))\n",
    "        for user,user_items in train_set.items():\n",
    "            samples = randomSelectNegativeSample(user_items,movies_pool)\n",
    "            for movie,rui in samples.items():\n",
    "                user_latent = user_p[user]\n",
    "                movie_latent = movie_q[movie]\n",
    "                user_p[user] += learning_rate * (movie_latent - l*user_latent)\n",
    "                movie_q[movie] += learning_rate * (user_latent - l*movie_latent)\n",
    "        loss = loss(samples,l,user_p,movie_q)\n",
    "        print(\"第{}轮,loss is {}\".format(epoch,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(train_data,k):\n",
    "    user_p = {}\n",
    "    movie_q = {}\n",
    "    movie_pool = set()\n",
    "    print(\"初始化参数...\")\n",
    "    for user,movies in train_data.items():\n",
    "        user_p[user] = np.random.normal(size=(k))\n",
    "        for movie in movies.items():\n",
    "            movie_pool.add(movie[0])\n",
    "    for movie in movie_pool:\n",
    "        movie_q[movie] = np.random.normal(size=(k))\n",
    "    return user_p,movie_q,movie_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166907 833302\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def load_data(users_path,movies_path,rating_path):\n",
    "    \n",
    "    def read_users():\n",
    "        \"\"\"(user_id:(gender,age,occupation))\"\"\"\n",
    "        users = {}\n",
    "        with open(users_path,'r') as f:\n",
    "            users = {line.split(\"::\")[0]:line.split(\"::\")[1:-1] for line in f.readlines()}\n",
    "        return users\n",
    "    def read_movies():\n",
    "        \"\"\"(movie_id:(title,genres))\"\"\"\n",
    "        movies = {}\n",
    "        with open(movies_path,'r') as f:\n",
    "            movies = {line.split(\"::\")[0]: line.split(\"::\")[1:] for line in f.readlines()}\n",
    "        return movies\n",
    "    def read_ratings():\n",
    "        \"\"\"{user_id:{movie_id: rating}}\"\"\"\n",
    "        ratings = dict()\n",
    "        with open(rating_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                user,movie,rating,_ = line.split('::')\n",
    "                ratings.setdefault(user,{})\n",
    "                ratings[user][movie] = int(rating)\n",
    "        return ratings\n",
    "    return read_users(),read_movies(),read_ratings()\n",
    "def split_train_test(data,M,k,seed):\n",
    "    \"\"\"M折交叉验证\"\"\"\n",
    "    train_set = dict()\n",
    "    test_set = dict()\n",
    "    random.seed(seed)\n",
    "    test_count,train_count = 0,0\n",
    "    for user,movie_info in data.items():\n",
    "        for movie,rating in movie_info.items():\n",
    "            if random.randint(0,M) == k:\n",
    "                test_set.setdefault(user,{})\n",
    "                test_set[user][movie] = int(rating)\n",
    "                test_count += 1\n",
    "            else:\n",
    "                train_set.setdefault(user,{})\n",
    "                train_set[user][movie] = int(rating)\n",
    "                train_count += 1\n",
    "    print(test_count,train_count)\n",
    "    return train_set,test_set\n",
    "USERS_PATH = '../dataset/ml-1m/users.dat'\n",
    "MOVIES_PATH = '../dataset/ml-1m/movies.dat'\n",
    "RATINGS_PATH = '../dataset/ml-1m/ratings.dat'\n",
    "users,movies,ratings = load_data(USERS_PATH,MOVIES_PATH,RATINGS_PATH)\n",
    "train_set,test_set = split_train_test(ratings,5,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化参数...\n"
     ]
    }
   ],
   "source": [
    "user_p,movie_q,movies_pool = init(train_set,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.07494963,  0.87836205, -1.3196014 , -0.89899117, -0.05271024,\n",
       "        -0.33034091,  1.3926425 ,  1.29885764, -1.40680886, -0.22223479,\n",
       "        -0.04192161, -0.40425667, -0.70444912,  1.68396205,  0.00632103,\n",
       "        -0.61012895, -0.12796785,  0.06183218,  0.9484937 ,  1.04422228,\n",
       "        -0.22083501,  0.27943368, -0.14422907,  1.21328413, -1.49905804,\n",
       "         0.97199992, -0.43069356,  0.41795874,  0.94921952,  1.27208229,\n",
       "        -0.79262414, -1.09876046, -1.49824399,  0.09081167,  0.14226749,\n",
       "         0.3310094 , -1.0137267 , -0.68520335, -0.24961466, -0.51489675,\n",
       "         0.8029353 ,  1.40935446,  2.20096657, -0.32589617,  1.05467198,\n",
       "         1.64032945, -0.05308882,  0.48315537, -1.6158723 , -0.3648277 ,\n",
       "         1.05652649, -0.43412986,  0.10164002,  0.77415808, -0.02295959,\n",
       "        -1.6724066 , -1.95448864,  0.64540759,  0.15180863, -0.19981573,\n",
       "        -0.76902234,  0.07231744, -0.30062156,  0.65723427, -0.33843025,\n",
       "         0.89257102,  2.50083823, -1.2124902 , -2.2458555 ,  0.18045804,\n",
       "        -1.49977094, -0.51040546, -0.42181109, -0.84433616, -1.32898689,\n",
       "        -0.46823334, -0.65248261,  0.15018863, -0.69914253, -0.26507478,\n",
       "         0.1813829 , -1.23236591,  1.64787977,  1.08250831,  0.42357409,\n",
       "        -0.72277986,  0.03706982, -0.69678122, -0.39485594,  0.20827775,\n",
       "         2.98027749,  1.36908215, -0.62631868,  2.00817001, -0.83253483,\n",
       "         0.06176717,  0.66327998, -0.23195583, -0.72591099,  0.00920164]),\n",
       " array([ 1.04885987,  1.22911936,  0.04376203, -1.18597349, -0.54312942,\n",
       "        -0.05673768, -1.28015564,  0.96597391,  0.29951035, -0.98998878,\n",
       "         1.26259172,  0.25213555,  0.12352738, -0.70426455,  1.2846153 ,\n",
       "        -1.10823295,  1.73594972, -0.10972074, -0.17427727,  1.25872606,\n",
       "         0.15211627, -0.22661723,  0.36166377,  0.66689303, -1.54364364,\n",
       "        -0.32844116, -1.00905829,  0.30762164,  1.94846633, -1.42879836,\n",
       "        -0.61343235,  0.50094117,  0.28342494, -0.19399432, -0.67207762,\n",
       "         0.55341172, -1.26640662,  1.5130087 ,  0.3597596 , -1.63079676,\n",
       "         1.14511009, -0.97759009, -0.28079766,  1.70232731,  0.4588847 ,\n",
       "         0.92615796, -1.56407295, -2.17641744, -0.78612627,  0.56596682,\n",
       "        -0.09101306,  1.69023829,  0.20355869,  1.50927831,  0.80556582,\n",
       "         0.75912681, -0.00892193,  0.45132712,  0.23893919,  0.88287653,\n",
       "        -0.44710282, -0.26592858, -1.12366084, -0.74825896,  1.09093714,\n",
       "         0.63422942,  1.22489144,  0.53735567,  1.23165176, -0.988056  ,\n",
       "         1.25985012,  0.12125111,  0.69448893,  0.37663198, -1.36662237,\n",
       "         0.07600183, -2.23632318, -0.9662859 , -0.87021538,  0.76780429,\n",
       "        -1.45541398, -0.19330913, -1.64749483, -1.63421269,  0.03862529,\n",
       "        -1.22148668,  0.87965811, -1.47374886,  0.20338892,  1.24616736,\n",
       "        -0.55311768,  1.6137032 ,  0.40899562, -0.233607  ,  0.45537456,\n",
       "         0.01865416,  0.81049581, -1.10490653, -1.6956589 , -2.15873242]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_p['1'],movie_q['661']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮训练begainning...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-fb77a3a4633f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovie_q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-7bcc55fe3d4e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(user_p, movie_q, movies_pool, epoches, learning_rate, l)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第{}轮训练begainning...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_items\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomSelectNegativeSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_items\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovies_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrui\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0muser_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d6ffff38f22e>\u001b[0m in \u001b[0;36mrandomSelectNegativeSample\u001b[0;34m(items, item_pool)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mn_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mn_negative\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(user_p,movie_q,list(movies_pool),500,learning_rate=0.02,l=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def recommand(user):\n",
    "    def predict(user,movie):\n",
    "        return np.dot(user_p[user],movie_p[movie])\n",
    "    rank = defaultdict(int)\n",
    "    for movie in list(movies_pool):\n",
    "        rank[movie] = predict(user,movie)\n",
    "    return sorted(rank.items(),key=itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(train,test,N):\n",
    "    hit = 0\n",
    "    for user in train.keys():\n",
    "        real = test[user] if user in test else []\n",
    "        recommand_items = recommand(user)[:N]\n",
    "        for item in recommand_items:\n",
    "            if item[0] in real:\n",
    "                hit += 1\n",
    "    print('hit:%d'% hit)\n",
    "    return hit\n",
    "# precision\n",
    "def Precision(train,hit,N):\n",
    "    print('sum:%d' % (len(train.keys()) * N))\n",
    "    return hit / len(train.keys()) * N\n",
    "# recall\n",
    "def Recall(train,test,hit):\n",
    "    recommands = 0\n",
    "    for user in train.keys():\n",
    "        real = test[user] if user in test else []\n",
    "        recommands += len(real)\n",
    "    print('sum_real: %d' % recommands)\n",
    "    return hit / recommands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_total = hit(train_set,test_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision(train_set,hit,10),Recall(train_set,hit,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}